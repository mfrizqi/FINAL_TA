{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv \n",
    "import math\n",
    "import joblib\n",
    "import pickle\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as stat\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concate data padel with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from csv into pandas DataFrame\n",
    "dfPadel = pd.read_csv(\"data/padel_desc.csv\")\n",
    "dtRawIC50 = pd.read_csv(\"data/pIC50_target.csv\")\n",
    "dtIC50 = dtRawIC50['pIC50']\n",
    "\n",
    "# Concatenate data dataframe (Padel,Cdk,Target)\n",
    "df = pd.concat([dfPadel,dtIC50], axis=1)\n",
    "df = df.drop(columns = ['Name'])\n",
    "\n",
    "# Export concatenated data\n",
    "# df.to_csv (r'data\\all_data.csv',index=False, header=True,sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train & Test + PCC Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop for finding correlation combination\n",
    "for i in range(10):\n",
    "    # Divide into training data and test data\n",
    "    dfTrain = df.sample(frac=0.8,random_state=i)\n",
    "    dfTest = df.drop(dfTrain.index)\n",
    "\n",
    "    # Find 100 descriptors with strongest correlation with pIC50\n",
    "    train_corr = dfTrain.corr()\n",
    "    train_corr = train_corr.iloc[:-1,[-1]]\n",
    "    train_corr.sort_values(\"pIC50\", ascending = False, inplace = True)\n",
    "    train_corr = train_corr.iloc[:100,:]\n",
    "\n",
    "    # Check for WTPT-3 only\n",
    "    if train_corr.index[0] == \"WTPT-3\":\n",
    "        print(\"i: %04d\"%i)\n",
    "        # Dump training and test data\n",
    "        dfTrain.to_pickle(\"./pickle/train_%04d.pkl\"%i)\n",
    "        dfTest.to_pickle(\"./pickle/test_%04d.pkl\"%i)\n",
    "        # Dump correlation data\n",
    "        train_corr.to_csv(r'data/dataCorr_%04d.pkl.csv'%i, index= None, header = True)\n",
    "        # Dump list of 100 strongest des\n",
    "        corr_100 = train_corr.index.values.tolist()[:100]\n",
    "        with open('./pickle/corr100_%04d.pkl'%i, 'wb') as f:\n",
    "            pickle.dump(corr_100, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection : SA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SA Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceptanceProbability (bestMSE, newMSE, temp , K):\n",
    "        # If the new solution is worse, calculate an acceptance probability\n",
    "        return np.exp( K * (newMSE - bestMSE) / temp)\n",
    "    \n",
    "def calcMSE(combDesc, x_train, x_val, y_train, y_val, model):\n",
    "    x_train_slice = x_train.iloc[:,combDesc]\n",
    "    x_val_slice = x_val.iloc[:,combDesc]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(x_train_slice)\n",
    "    scale_x_train = scaler.transform(x_train_slice)\n",
    "    scale_x_val = scaler.transform(x_val_slice)\n",
    "    \n",
    "    model.fit(scale_x_train, y_train)\n",
    "    y_pred = model.predict(scale_x_val)\n",
    "    return mean_squared_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SA Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59, 100), (15, 100), (59, 1), (15, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs = []\n",
    "cor1 = joblib.load('./p/corr100_0003.pkl')\n",
    "cor2 = joblib.load('./p/corr100_0005.pkl')\n",
    "cor3 = joblib.load('./p/corr100_0006.pkl')\n",
    "cor4 = joblib.load('./p/corr100_0007.pkl')\n",
    "cor5 = joblib.load('./p/corr100_0008.pkl')\n",
    "\n",
    "trains = []\n",
    "tr1 = joblib.load('./p/train_0003.pkl')\n",
    "tr2 = joblib.load('./p/train_0005.pkl')\n",
    "tr3 = joblib.load('./p/train_0006.pkl')\n",
    "tr4 = joblib.load('./p/train_0007.pkl')\n",
    "tr5 = joblib.load('./p/train_0008.pkl')\n",
    "\n",
    "corrs.extend([cor1, cor2, cor3, cor4, cor5])\n",
    "trains.extend([tr1, tr2, tr3, tr4, tr5])\n",
    "\n",
    "#change index for data\n",
    "corr_100 = corrs[0]\n",
    "dft = trains[0]\n",
    "\n",
    "train = dft.loc[:,corr_100]\n",
    "train[\"pIC50\"] = dft.iloc[:, -1]\n",
    "descName = train.columns.values\n",
    "\n",
    "trained, val = train_test_split(train, test_size = 0.2, random_state = 10)\n",
    "\n",
    "x_train = trained.iloc[:,:-1]\n",
    "x_val = val.iloc[:,:-1]\n",
    "y_train = trained.iloc[:, [-1]]\n",
    "y_val = val.iloc[:,[-1]]\n",
    "\n",
    "model = LinearRegression()\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|████▏                                                                              | 1/20 [01:16<24:15, 76.61s/it]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b85e007b4b00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[1;31m# Create new solution & new MSE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mnewSol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescNum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                 \u001b[0mnewMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalcMSE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewSol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m                 \u001b[0mdeltaMSE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnewMSE\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbestMSE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-b6fe2e123a34>\u001b[0m in \u001b[0;36mcalcMSE\u001b[1;34m(combDesc, x_train, x_val, y_train, y_val, model)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mscale_x_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val_slice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale_x_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale_x_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\muhammad fajar rizqi\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0m\u001b[0;32m    492\u001b[0m                          y_numeric=True, multi_output=True)\n\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\muhammad fajar rizqi\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\muhammad fajar rizqi\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\muhammad fajar rizqi\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\muhammad fajar rizqi\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "combos = [5,10,15,20,25]\n",
    "\n",
    "for k in tqdm(range(5)):\n",
    "\n",
    "    ## INTO DE SA DE LA'SOIN MODDED ##\n",
    "    descNum = combos[k]\n",
    "    descMSE_descNum = []\n",
    "\n",
    "    for j in tqdm(range(20)):\n",
    "        # Initialize Values\n",
    "        initTemp, temp = 100, 100\n",
    "        tempEnd = 0.1\n",
    "        cooling_rate = 0.98\n",
    "        iteration = 50\n",
    "\n",
    "        # Simulated Annealing\n",
    "        bestList = []\n",
    "        bestMSEList = []\n",
    "        tempChange = []\n",
    "        sounded = True\n",
    "\n",
    "        # Initialize solution & Best MSE (Random descNum descriptor)\n",
    "        bestSol = np.random.choice(x_train.shape[1],descNum, replace=False)\n",
    "        bestSol = list(bestSol)\n",
    "        bestSol.sort()\n",
    "\n",
    "        # First MSE\n",
    "        bestMSE = calcMSE(bestSol, x_train, x_val, y_train, y_val, model)\n",
    "        while temp > tempEnd:\n",
    "            for i in range(iteration):\n",
    "\n",
    "                # Create new solution & new MSE\n",
    "                newSol = np.random.choice(x_train.shape[1], descNum, replace=False)\n",
    "                newMSE = calcMSE(newSol, x_train, x_val, y_train, y_val, model)\n",
    "                deltaMSE = newMSE - bestMSE\n",
    "                \n",
    "                # New solution is better based on MSE value\n",
    "                if newMSE < bestMSE :\n",
    "                    bestMSE = newMSE\n",
    "                    bestSol = newSol\n",
    "                    bestList.append([bestMSE,bestSol])\n",
    "                    tempChange.append(temp)\n",
    "                    bestMSEList.append(bestMSE)\n",
    "                    \n",
    "                #Probability to accept bad solution\n",
    "                else :\n",
    "                    K = (initTemp * np.log(0.8)) / deltaMSE\n",
    "                    if acceptanceProbability (bestMSE, newMSE, temp , K) > np.random.rand(0,1):\n",
    "                        bestMSE = newMSE\n",
    "                        bestSol = newSol\n",
    "                        bestList.append([bestMSE,bestSol])\n",
    "                        tempChange.append(temp)\n",
    "                        bestMSEList.append(bestMSE)\n",
    "\n",
    "            temp *= cooling_rate\n",
    "\n",
    "        descMSE_descNum.append([bestList[-1][0],bestList[-1][1],bestMSEList,tempChange])\n",
    "       \n",
    "    # Extracting results\n",
    "    df_SA = pd.DataFrame(descMSE_descNum)\n",
    "    df_SA.columns=[\"MSE\",\"solution\",\"growth\", \"temp\"]\n",
    "    df_SA.reset_index(drop=True, inplace= True)\n",
    "\n",
    "    # Sort values\n",
    "    df_SA_sort = df_SA.copy()\n",
    "    df_SA_sort.sort_values('MSE', inplace=True)\n",
    "\n",
    "    # Get Descriptors name    \n",
    "    bestDescriptor = []\n",
    "    for i in df_SA_sort.iloc[0,1]:\n",
    "        bestDescriptor.append(descName[i])\n",
    "\n",
    "    bestSAGrowth = df_SA_sort.iloc[0,2]\n",
    "        \n",
    "    df_SA.to_pickle(\"./p/raw_0003_%02d.pkl\"%k)\n",
    "    joblib.dump(bestDescriptor, \"./p/best_0003_%02.pkl\"%k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
